{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h20.automl \n",
    "### Using h2o.automl to predict house sale precises for Kaggle contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Downloading the contest data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "otrain = pd.read_csv('train_clean.csv')\n",
    "otest= pd.read_csv('test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "Converting the \"SalePrices\" variable to log(1+x) form. This step is performed for linearizing/normalizing the data for easier model development. Detailed steps and graphs to show this change are shown in the housing jupyter file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "otrain[\"SalePrice\"] = np.log1p(otrain[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "Using h2o to develop the models. Automl feature in h2o basically runs all types of models with random features. This is a quick and easy way to see which type of model may be best suited for any particular dataset, and then further analysis can be performed only on that type of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>15 hours 21 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 23 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_architmanuja_t4nwyz</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.146 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>AutoML, Amazon S3, Algos, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         15 hours 21 mins\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.1\n",
       "H2O cluster version age:    2 months and 23 days\n",
       "H2O cluster name:           H2O_from_python_architmanuja_t4nwyz\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.146 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         AutoML, Amazon S3, Algos, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(min_mem_size='2G', max_mem_size='4G')\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = h2o.H2OFrame(otrain)\n",
    "test = h2o.H2OFrame(otest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into 70% training and 30% validation\n",
    "train, valid = train.split_frame([0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the x and y variables/columns\n",
    "ColsToDrop = ['id']\n",
    "y = 'SalePrice'\n",
    "X = [name for name in train.columns if name not in [y] + ColsToDrop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# performing the h2o.automl feature - developing the models\n",
    "from h2o.automl import H2OAutoML\n",
    "aml = H2OAutoML(max_models=250, sort_metric = \"RMSLE\", nfolds = 3, seed=123)\n",
    "aml.train(x=X, y=y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">    rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190624_075216</td><td style=\"text-align: right;\">               0.0169765</td><td style=\"text-align: right;\">0.130294</td><td style=\"text-align: right;\">0.0169765</td><td style=\"text-align: right;\">0.0814412</td><td style=\"text-align: right;\">0.0100683</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190624_075216   </td><td style=\"text-align: right;\">               0.0177232</td><td style=\"text-align: right;\">0.133129</td><td style=\"text-align: right;\">0.0177232</td><td style=\"text-align: right;\">0.0817716</td><td style=\"text-align: right;\">0.0102697</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190624_075216_model_22</td><td style=\"text-align: right;\">               0.0179866</td><td style=\"text-align: right;\">0.134114</td><td style=\"text-align: right;\">0.0179866</td><td style=\"text-align: right;\">0.0870901</td><td style=\"text-align: right;\">0.0103632</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190624_075216                       </td><td style=\"text-align: right;\">               0.0187382</td><td style=\"text-align: right;\">0.136888</td><td style=\"text-align: right;\">0.0187382</td><td style=\"text-align: right;\">0.0932486</td><td style=\"text-align: right;\">0.0106476</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190624_075216_model_23</td><td style=\"text-align: right;\">               0.0190205</td><td style=\"text-align: right;\">0.137915</td><td style=\"text-align: right;\">0.0190205</td><td style=\"text-align: right;\">0.0920885</td><td style=\"text-align: right;\">0.0106967</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190624_075216                       </td><td style=\"text-align: right;\">               0.0189531</td><td style=\"text-align: right;\">0.13767 </td><td style=\"text-align: right;\">0.0189531</td><td style=\"text-align: right;\">0.0934635</td><td style=\"text-align: right;\">0.0107056</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190624_075216_model_16         </td><td style=\"text-align: right;\">               0.0189193</td><td style=\"text-align: right;\">0.137547</td><td style=\"text-align: right;\">0.0189193</td><td style=\"text-align: right;\">0.0921308</td><td style=\"text-align: right;\">0.0107222</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190624_075216                       </td><td style=\"text-align: right;\">               0.0191298</td><td style=\"text-align: right;\">0.13831 </td><td style=\"text-align: right;\">0.0191298</td><td style=\"text-align: right;\">0.0934249</td><td style=\"text-align: right;\">0.0107683</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190624_075216_model_10         </td><td style=\"text-align: right;\">               0.0192198</td><td style=\"text-align: right;\">0.138635</td><td style=\"text-align: right;\">0.0192198</td><td style=\"text-align: right;\">0.0932753</td><td style=\"text-align: right;\">0.0107812</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190624_075216_model_4          </td><td style=\"text-align: right;\">               0.0191835</td><td style=\"text-align: right;\">0.138505</td><td style=\"text-align: right;\">0.0191835</td><td style=\"text-align: right;\">0.0926702</td><td style=\"text-align: right;\">0.0108045</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the top 10 models and their associated deviance and errors - since the Kaggle contest is compared based on RMSLE, \n",
    "# our models are also sorted based on lowest RMSLE\n",
    "lb = aml.leaderboard\n",
    "lb.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior2nd' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior1st' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'SaleType' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'GarageYrBlt' has levels not trained on: [(2.19e+03,2.21e+03]]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Functional' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'MSZoning' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'KitchenQual' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "# creating predictions for the test dataset based on the best model \n",
    "bestmodel = aml.leader\n",
    "preds = bestmodel.predict(test)\n",
    "predictions = h2o.as_list(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "Creating the submission file for submitting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission output\n",
    "submission3 = pd.concat([otest.Id.reset_index(drop=True), predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names\n",
    "submission3 = submission3.rename(index=str, columns={\"predict\": \"SalePrice\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the SalePrice variable from log(x+1) values back to normal\n",
    "submission3[\"SalePrice\"] = np.expm1(submission3[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data as a csv for easier submission\n",
    "submission3.to_csv(\"submission_automl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Best Model gave a score of 0.12244 on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "Choosing the second best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "SecondBest = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior2nd' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior1st' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'SaleType' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'GarageYrBlt' has levels not trained on: [(2.19e+03,2.21e+03]]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Functional' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'MSZoning' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'KitchenQual' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "preds = SecondBest.predict(test)\n",
    "predictions = h2o.as_list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission output\n",
    "submission3 = pd.concat([otest.Id.reset_index(drop=True), predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names\n",
    "submission3 = submission3.rename(index=str, columns={\"predict\": \"SalePrice\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the SalePrice variable from log(x+1) values back to normal\n",
    "submission3[\"SalePrice\"] = np.expm1(submission3[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data as a csv for easier submission\n",
    "submission3.to_csv(\"submission_automl_secondbest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Second Best Model gave a score of 0.12649 on Kaggle (worse than the best model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "Taking the average of values shown by best model and second best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior2nd' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior1st' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'SaleType' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'GarageYrBlt' has levels not trained on: [(2.19e+03,2.21e+03]]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Functional' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'MSZoning' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'KitchenQual' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "#running predictions on the best model again to use for calculating the average\n",
    "bestmodel = aml.leader\n",
    "preds = bestmodel.predict(test)\n",
    "predictions = h2o.as_list(preds)\n",
    "submission3 = pd.concat([otest.Id.reset_index(drop=True), predictions], axis=1)\n",
    "submission3 = submission3.rename(index=str, columns={\"predict\": \"SalePrice\"})\n",
    "submission3[\"SalePrice\"] = np.expm1(submission3[\"SalePrice\"])\n",
    "BestModelValues = submission3[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior2nd' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Exterior1st' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'SaleType' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'GarageYrBlt' has levels not trained on: [(2.19e+03,2.21e+03]]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'Functional' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'MSZoning' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "C:\\Users\\architmanuja\\Anaconda3\\lib\\site-packages\\h2o\\job.py:69: UserWarning: Test/Validation dataset column 'KitchenQual' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "#running predictions on the second best model again to use for calculating the average\n",
    "preds = SecondBest.predict(test)\n",
    "predictions = h2o.as_list(preds)\n",
    "submission3 = pd.concat([otest.Id.reset_index(drop=True), predictions], axis=1)\n",
    "submission3 = submission3.rename(index=str, columns={\"predict\": \"SalePrice\"})\n",
    "submission3[\"SalePrice\"] = np.expm1(submission3[\"SalePrice\"])\n",
    "SecondBestModelValues = submission3[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the Average of the top two best models and saving it into a new variable\n",
    "pre = pd.Series(range(1461,2920))\n",
    "AverageValues = (BestModelValues + SecondBestModelValues)/2\n",
    "AvgCSV = pd.DataFrame(list(zip(pre,AverageValues)),columns=['Id', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to a csv\n",
    "AvgCSV.to_csv(\"submission_automl_AVERAGEMODEL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Average of the Best and the Second Best Models gave a score of 0.12170 on Kaggle (Best so far for StackedEnsemble Models using h2o.automl feature). This put us in the top 28% rank at the time of the submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
